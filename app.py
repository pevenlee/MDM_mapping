import streamlit as st
import pandas as pd
import json
import time
import os
import gc
from google import genai
from google.genai import types
from rapidfuzz import process, fuzz 

# ================= 1. é…ç½®ä¸åˆå§‹åŒ– =================

st.set_page_config(page_title="LinkMed Matcher Pro", layout="wide", page_icon="âš¡")

try:
    FIXED_API_KEY = st.secrets["GENAI_API_KEY"]
except:
    FIXED_API_KEY = "" 

# âœ… æŒ‡å‘ Excel æ–‡ä»¶
LOCAL_MASTER_FILE = "MDM_retail.xlsx"

# ================= 2. æ ¸å¿ƒå·¥å…·å‡½æ•° =================

@st.cache_resource
def get_client():
    if not FIXED_API_KEY: return None
    return genai.Client(api_key=FIXED_API_KEY, http_options={'api_version': 'v1beta'})

def safe_generate(client, prompt, response_schema=None):
    if client is None:
        return {"error": "API Key æœªé…ç½®"}
    try:
        config = types.GenerateContentConfig(
            response_mime_type="application/json",
            response_schema=response_schema
        )
        response = client.models.generate_content(
            model="gemini-2.0-flash", 
            contents=prompt,
            config=config
        )
        return json.loads(response.text)
    except Exception as e:
        return {"error": str(e)}

@st.cache_resource(show_spinner=False)
def load_master_data():
    """åŠ è½½ä¸»æ•°æ®ï¼Œæ”¯æŒ xlsx å’Œ csvï¼Œå¸¦å†…å­˜ä¼˜åŒ–"""
    if os.path.exists(LOCAL_MASTER_FILE):
        try:
            # å¼ºåˆ¶è°ƒç”¨åƒåœ¾å›æ”¶ï¼Œé‡Šæ”¾æ—§å†…å­˜
            gc.collect()
            
            # âœ… æ ¹æ®åç¼€è‡ªåŠ¨é€‰æ‹©è¯»å–å¼•æ“
            if LOCAL_MASTER_FILE.endswith('.xlsx'):
                # engine='openpyxl' æ›´ç¨³å®š
                df = pd.read_excel(LOCAL_MASTER_FILE, engine='openpyxl')
            else:
                df = pd.read_csv(LOCAL_MASTER_FILE)
                
            # æ¸…æ´—ï¼šå»é‡ esidï¼Œå¹¶ç¡®ä¿æ ‡å‡†åç§°æ˜¯å­—ç¬¦ä¸²ä¸”å»é™¤é¦–å°¾ç©ºæ ¼
            if 'esid' in df.columns:
                df = df.drop_duplicates(subset=['esid'])
            if 'æ ‡å‡†åç§°' in df.columns:
                df['æ ‡å‡†åç§°'] = df['æ ‡å‡†åç§°'].astype(str).str.strip()
                
            return df
        except Exception as e:
            st.error(f"è¯»å–ä¸»æ•°æ®æ–‡ä»¶å‡ºé”™: {e}")
            return pd.DataFrame()
    else:
        # æ–‡ä»¶ä¸å­˜åœ¨æ—¶ä¸æŠ¥é”™ï¼Œåªè¿”å›ç©ºï¼Œåœ¨UIå±‚æç¤º
        return pd.DataFrame()

def smart_map_columns(client, df_user, master_cols):
    sample_data = df_user.head(3).to_markdown(index=False)
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªæ•°æ®æ˜ å°„ä¸“å®¶ã€‚
    ã€ä¸»æ•°æ®æ ¸å¿ƒåˆ—ã€‘: {master_cols}
    ã€ç”¨æˆ·ä¸Šä¼ æ•°æ®é¢„è§ˆã€‘:
    {sample_data}
    è¯·åˆ†æç”¨æˆ·çš„åˆ—åï¼Œæ‰¾å‡ºä»£è¡¨â€œè¯æˆ¿åç§°â€çš„åˆ—å’Œâ€œåœ°å€â€åˆ—ã€‚
    è¿”å› JSON: {{ "name_col": "...", "addr_col": "..." }}
    """
    res = safe_generate(client, prompt)
    return res

def get_candidates(query, choices, limit=5):
    if not isinstance(query, str) or not query.strip():
        return []
    results = process.extract(query, choices, limit=limit, scorer=fuzz.WRatio)
    return [r[2] for r in results]

def ai_match_row(client, user_row, name_col, addr_col, candidates_df):
    user_name = str(user_row.get(name_col, ''))
    user_addr = str(user_row.get(addr_col, '')) if addr_col else "æœªçŸ¥"
    
    cols_to_keep = ['esid', 'æ ‡å‡†åç§°', 'åˆ«å', 'çœ', 'å¸‚', 'åŒº', 'åœ°å€']
    valid_cols = [c for c in cols_to_keep if c in candidates_df.columns]
    candidates_json = candidates_df[valid_cols].to_json(orient="records", force_ascii=False)
    
    prompt = f"""
    ã€ä»»åŠ¡ã€‘åˆ¤æ–­â€œå¾…åŒ¹é…æ•°æ®â€æ˜¯å¦ä¸â€œå€™é€‰ä¸»æ•°æ®â€æ˜¯åŒä¸€å®¶è¯åº—ã€‚
    ã€å¾…åŒ¹é…ã€‘åç§°: "{user_name}", åœ°å€: "{user_addr}"
    ã€å€™é€‰é›†ã€‘: {candidates_json}
    ã€è§„åˆ™ã€‘ä¼˜å…ˆåŒ¹é…åœ°å€ï¼ˆçœå¸‚åŒº+è¯¦ç»†åœ°å€ï¼‰æœ€æ¥è¿‘çš„å€™é€‰ã€‚
    ã€è¾“å‡º JSONã€‘: {{ "match_esid": "...", "match_name": "...", "confidence": "High/Medium/Low", "reason": "..." }}
    """
    return safe_generate(client, prompt)

# ================= 3. é¡µé¢ UI =================

# 1. å…ˆæ¸²æŸ“ Headerï¼Œç¡®ä¿ App å¯åŠ¨æ—¶æœ‰å“åº”ï¼Œé˜²æ­¢ Health Check å¤±è´¥
st.markdown("""
    <style>
    .stApp {background-color: #F8F9FA;}
    .main-header {font-size: 26px; font-weight: bold; color: #1E3A8A; margin-bottom: 20px;}
    .step-card {background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 5px rgba(0,0,0,0.05); margin-bottom: 15px;}
    .count-box {
        background-color: #e3f2fd; color: #0d47a1; padding: 10px 15px; 
        border-radius: 5px; font-weight: bold; border-left: 5px solid #1976d2;
        margin: 10px 0; display: inline-block;
    }
    </style>
    <div class="main-header">âš¡ LinkMed æé€ŸåŒ¹é… (Pro)</div>
""", unsafe_allow_html=True)

client = get_client()

# 2. å»¶è¿ŸåŠ è½½ä¸»æ•°æ® (é˜²æ­¢å¯åŠ¨è¶…æ—¶)
df_master = pd.DataFrame() # åˆå§‹åŒ–ä¸ºç©º
if os.path.exists(LOCAL_MASTER_FILE):
    with st.spinner(f"æ­£åœ¨åŠ è½½ä¸»æ•°æ®èµ„æº: {LOCAL_MASTER_FILE}..."):
        df_master = load_master_data()
else:
    st.warning(f"âš ï¸ æœªæ£€æµ‹åˆ°ä¸»æ•°æ®æ–‡ä»¶: `{LOCAL_MASTER_FILE}`ã€‚è¯·å°†æ–‡ä»¶ä¸Šä¼ åˆ°é¡¹ç›®æ ¹ç›®å½•ã€‚")

# --- Sidebar ---
with st.sidebar:
    st.header("ğŸ—„ï¸ ä¸»æ•°æ®çœ‹æ¿")
    if not df_master.empty:
        st.success(f"âœ… å·²åŠ è½½ {len(df_master)} æ¡è®°å½•")
        st.caption(f"æ¥æº: {LOCAL_MASTER_FILE}")
    else:
        st.info("ç­‰å¾…æ•°æ®åŠ è½½...")

# --- Step 1: ä¸Šä¼  ---
st.markdown('<div class="step-card"><h3>ğŸ“‚ 1. ä¸Šä¼ å¾…æ¸…æ´—æ–‡ä»¶</h3></div>', unsafe_allow_html=True)
uploaded_file = st.file_uploader("æ”¯æŒ Excel/CSV", type=['xlsx', 'csv'])

if uploaded_file and not df_master.empty:
    try:
        if uploaded_file.name.endswith('.csv'):
            df_user = pd.read_csv(uploaded_file)
        else:
            df_user = pd.read_excel(uploaded_file)
        
        file_rows = len(df_user)
        st.markdown(f'<div class="count-box">ğŸ“Š è¯»å–æˆåŠŸ: å…± {file_rows} è¡Œæ•°æ®</div>', unsafe_allow_html=True)
        # ä¿®å¤è­¦å‘Šï¼šç§»é™¤ use_container_widthï¼Œæ”¹ç”¨é»˜è®¤è¡Œä¸ºæˆ– width å‚æ•°
        st.dataframe(df_user.head(3), hide_index=True)
        
        # --- Step 2: æ˜ å°„ ---
        st.markdown('<div class="step-card"><h3>ğŸ¤– 2. æ™ºèƒ½å­—æ®µæ˜ å°„</h3></div>', unsafe_allow_html=True)
        col1, col2 = st.columns(2)
        
        if 'map_config' not in st.session_state:
            with st.spinner("AI æ­£åœ¨åˆ†æè¡¨å¤´..."):
                st.session_state.map_config = smart_map_columns(client, df_user, df_master.columns.tolist())
        
        map_res = st.session_state.map_config
        all_cols = df_user.columns.tolist()
        
        with col1:
            default_name = map_res.get('name_col') if map_res.get('name_col') in all_cols else all_cols[0]
            target_name_col = st.selectbox("ğŸ“ è¯æˆ¿åç§°åˆ—", all_cols, index=all_cols.index(default_name))
            
        with col2:
            default_addr = map_res.get('addr_col')
            default_idx = all_cols.index(default_addr) if default_addr in all_cols else None
            target_addr_col = st.selectbox("ğŸ  åœ°å€åˆ— (å¯é€‰ï¼Œæé«˜ç²¾åº¦)", [None] + all_cols, index=default_idx if default_idx else 0)

        # --- Step 3: åŒ¹é… ---
        st.markdown('<div class="step-card"><h3>ğŸš€ 3. æ‰§è¡ŒåŒ¹é…</h3></div>', unsafe_allow_html=True)
        
        run_btn = st.button(f"å¼€å§‹åŒ¹é… ({file_rows} è¡Œ)", type="primary", use_container_width=True)
        
        if run_btn:
            results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # âœ… ä¼˜åŒ–ç­–ç•¥: æ„å»ºå…¨å­—åŒ¹é…å­—å…¸ (å·²åŠ å…¥å»é‡é€»è¾‘)
            # 1. æ˜¾å¼å»é™¤é‡å¤çš„'æ ‡å‡†åç§°'ï¼Œä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„è¡Œ
            df_master_unique = df_master.drop_duplicates(subset=['æ ‡å‡†åç§°'], keep='first')
            
            # 2. å®‰å…¨è½¬æ¢ä¸ºå­—å…¸ï¼Œé¿å… ValueError
            master_exact_lookup = df_master_unique.set_index('æ ‡å‡†åç§°').to_dict('index')
            
            # å‡†å¤‡æ¨¡ç³Šæœç´¢çš„ choices
            master_choices = df_master['æ ‡å‡†åç§°'].fillna('').astype(str).to_dict()
            
            exact_count = 0
            model_count = 0
            
            for idx, row in df_user.iterrows():
                raw_name = str(row[target_name_col]).strip()
                
                # --- æ ¸å¿ƒé€»è¾‘: å…ˆè¯•å…¨å­—åŒ¹é… ---
                if raw_name in master_exact_lookup:
                    # ğŸ¯ å‘½ä¸­!
                    match_data = master_exact_lookup[raw_name]
                    res_row = {
                        "åŸå§‹è¾“å…¥": raw_name,
                        "åŒ¹é…ESID": match_data.get('esid'),
                        "åŒ¹é…æ ‡å‡†å": raw_name,
                        "ç½®ä¿¡åº¦": "High",
                        "ç†ç”±": "å®Œå…¨åŒ¹é… (Exact Match)",
                        "åŒ¹é…æ–¹å¼": "å…¨å­—åŒ¹é…"
                    }
                    exact_count += 1
                    time.sleep(0.005) 
                    
                else:
                    # ğŸ¤– æœªå‘½ä¸­ -> è¿›å…¥æ¨¡å‹åŒ¹é…
                    candidate_indices = get_candidates(raw_name, master_choices, limit=5)
                    
                    if not candidate_indices:
                        res_row = {
                            "åŸå§‹è¾“å…¥": raw_name, "åŒ¹é…ESID": None, "åŒ¹é…æ ‡å‡†å": None, 
                            "ç½®ä¿¡åº¦": "Low", "ç†ç”±": "æ— ç›¸ä¼¼å€™é€‰", "åŒ¹é…æ–¹å¼": "æ— ç»“æœ"
                        }
                    else:
                        candidates_df = df_master.loc[candidate_indices].copy()
                        ai_res = ai_match_row(client, row, target_name_col, target_addr_col, candidates_df)
                        
                        res_row = {
                            "åŸå§‹è¾“å…¥": raw_name,
                            "åŒ¹é…ESID": ai_res.get("match_esid"),
                            "åŒ¹é…æ ‡å‡†å": ai_res.get("match_name"),
                            "ç½®ä¿¡åº¦": ai_res.get("confidence", "Low"),
                            "ç†ç”±": ai_res.get("reason"),
                            "åŒ¹é…æ–¹å¼": "æ¨¡å‹åŒ¹é…"
                        }
                    model_count += 1
                
                results.append(res_row)
                
                # æ›´æ–°è¿›åº¦
                progress_bar.progress((idx + 1) / file_rows)
                status_text.text(f"[{idx+1}/{file_rows}] å¤„ç†ä¸­... {raw_name}")
            
            status_text.success(f"âœ… å®Œæˆ! å…¨å­—åŒ¹é…: {exact_count} | æ¨¡å‹åŒ¹é…: {model_count}")
            
            df_result = pd.DataFrame(results)
            df_final = pd.concat([df_user.reset_index(drop=True), df_result.drop(columns=["åŸå§‹è¾“å…¥"])], axis=1)
            
            def highlight_row(row):
                if row['åŒ¹é…æ–¹å¼'] == 'å…¨å­—åŒ¹é…':
                    return ['background-color: #d1fae5'] * len(row)
                elif row['ç½®ä¿¡åº¦'] == 'High':
                    return ['background-color: #fff3cd'] * len(row)
                else:
                    return [''] * len(row)

            # ä¿®å¤è­¦å‘Š: ç§»é™¤ use_container_width
            st.dataframe(df_result.style.apply(highlight_row, axis=1))
            csv = df_final.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœ", csv, "matched_result_pro.csv", "text/csv")

    except Exception as e:
        st.error(f"è¿è¡Œæ—¶é”™è¯¯: {str(e)}")
        st.exception(e)

else:
    if df_master.empty and os.path.exists(LOCAL_MASTER_FILE):
         st.info("æ­£åœ¨åˆå§‹åŒ–æ•°æ®å¼•æ“ï¼Œè¯·ç¨å€™...")