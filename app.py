import streamlit as st
import pandas as pd
import json
import time
import os
import gc
import math
from google import genai
from google.genai import types
from rapidfuzz import process, fuzz 

# ================= 1. é…ç½®ä¸åˆå§‹åŒ– =================

st.set_page_config(page_title="LinkMed Matcher Pro (Smart Logic)", layout="wide", page_icon="ğŸ§¬")

try:
    FIXED_API_KEY = st.secrets["GENAI_API_KEY"]
except:
    FIXED_API_KEY = "" 

LOCAL_MASTER_FILE = "MDM_retail.xlsx"

# --- Session State ---
if 'uploader_key' not in st.session_state: st.session_state.uploader_key = str(time.time())
if 'final_result_df' not in st.session_state: st.session_state.final_result_df = None
if 'match_stats' not in st.session_state: st.session_state.match_stats = {'exact': 0, 'high': 0, 'mid': 0, 'low': 0, 'no_match': 0}
# ä»»åŠ¡æµæ§åˆ¶
if 'prep_done' not in st.session_state: st.session_state.prep_done = False
if 'mapping_confirmed' not in st.session_state: st.session_state.mapping_confirmed = False
if 'df_exact' not in st.session_state: st.session_state.df_exact = None
if 'batches' not in st.session_state: st.session_state.batches = []
if 'total_rem' not in st.session_state: st.session_state.total_rem = 0
if 'accumulated_results' not in st.session_state: st.session_state.accumulated_results = []
if 'is_running' not in st.session_state: st.session_state.is_running = False
if 'current_batch_idx' not in st.session_state: st.session_state.current_batch_idx = 0
if 'stop_requested' not in st.session_state: st.session_state.stop_requested = False

# ================= 2. æ ¸å¿ƒå·¥å…·å‡½æ•° =================

def reset_app():
    """å®Œå…¨é‡ç½®"""
    keys = ['final_result_df', 'match_stats', 'prep_done', 'mapping_confirmed', 'df_exact', 
            'batches', 'total_rem', 'is_running', 'current_batch_idx', 'accumulated_results', 'stop_requested']
    for k in keys:
        if k in st.session_state: del st.session_state[k]
    st.session_state.uploader_key = str(time.time())
    st.rerun()

def request_stop():
    """è¯·æ±‚åœæ­¢"""
    st.session_state.stop_requested = True
    st.session_state.is_running = False

@st.cache_resource
def get_client():
    if not FIXED_API_KEY: return None
    return genai.Client(api_key=FIXED_API_KEY, http_options={'api_version': 'v1beta'})

def safe_generate(client, prompt, response_schema=None, retries=3):
    if client is None: return {"error": "API Key æœªé…ç½®"}
    wait_time = 2 
    for attempt in range(retries):
        try:
            config = types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=response_schema
            )
            response = client.models.generate_content(
                model="gemini-2.0-flash", 
                contents=prompt,
                config=config
            )
            try:
                return json.loads(response.text)
            except json.JSONDecodeError:
                return {"error": "JSONè§£æå¤±è´¥", "raw": response.text}
        except Exception as e:
            if "429" in str(e) or "503" in str(e):
                if attempt < retries - 1:
                    time.sleep(wait_time * (2 ** attempt))
                    continue
            return {"error": str(e)}
    return {"error": "Max retries reached"}

@st.cache_resource(show_spinner=False)
def load_master_data():
    if os.path.exists(LOCAL_MASTER_FILE):
        try:
            gc.collect()
            if LOCAL_MASTER_FILE.endswith('.xlsx'):
                df = pd.read_excel(LOCAL_MASTER_FILE, engine='openpyxl')
            else:
                df = pd.read_csv(LOCAL_MASTER_FILE)
            
            df = df.reset_index(drop=True)
            # ç¡®ä¿ä¸»æ•°æ®å…³é”®åˆ—å­˜åœ¨
            target_cols = ['æ ‡å‡†åç§°', 'çœ', 'å¸‚', 'åŒº', 'æœºæ„ç±»å‹', 'åœ°å€', 'è¿é”å“ç‰Œ']
            for col in target_cols:
                if col not in df.columns: df[col] = ''
                df[col] = df[col].astype(str).replace('nan', '').str.strip()
            
            # å»ºç«‹å¤šçº§ç´¢å¼•
            prov_groups = df.groupby('çœ').groups
            city_groups = df.groupby('å¸‚').groups
            dist_groups = df.groupby('åŒº').groups
            
            chain_groups = {}
            mask = df['è¿é”å“ç‰Œ'].str.len() > 1
            if mask.any():
                chain_groups = df[mask].groupby('è¿é”å“ç‰Œ').groups
            
            return df, prov_groups, city_groups, dist_groups, chain_groups
        except Exception as e:
            st.error(f"è¯»å–ä¸»æ•°æ®é”™è¯¯: {e}")
            return pd.DataFrame(), {}, {}, {}, {}
    else:
        return pd.DataFrame(), {}, {}, {}, {}

def smart_map_columns(client, df_user):
    user_cols = df_user.columns.tolist()
    sample_data = df_user.head(3).to_markdown(index=False)
    # ä¼˜åŒ–Promptï¼šè®©AIæ›´ç²¾å‡†è¯†åˆ«
    prompt = f"""
    åˆ†æè¯åº—æ•°æ®è¡¨å¤´ã€‚
    ç”¨æˆ·åˆ—å: {user_cols}
    é¢„è§ˆ: {sample_data}
    
    è¯·æ¨æ–­ä»¥ä¸‹å­—æ®µå¯¹åº”å“ªä¸€åˆ—ï¼ˆè‹¥æ— åˆ™nullï¼‰ï¼š
    1. name_col: è¯æˆ¿åç§°/ç»ˆç«¯å (æ ¸å¿ƒ)
    2. chain_col: è¿é”/å“ç‰Œ (å¦‚: æµ·ç‹æ˜Ÿè¾°, å¤§å‚æ—)
    3. prov_col: çœä»½
    4. city_col: åŸå¸‚
    5. dist_col: åŒº/å¿
    6. addr_col: è¯¦ç»†åœ°å€ (éå¸¸é‡è¦)
    
    è¾“å‡º JSON: {{ "name_col": "...", "chain_col": "...", "prov_col": "...", "city_col": "...", "dist_col": "...", "addr_col": "..." }}
    """
    res = safe_generate(client, prompt)
    if isinstance(res, list): res = res[0] if res else {}
    return res

def get_candidates_hierarchical(search_name, chain_name, df_master, prov_groups, city_groups, dist_groups, chain_groups, user_row, mapping):
    """
    ğŸŒŸ ç­–ç•¥æ ¸å¿ƒï¼šå…ˆæ ¹æ®åœ°ç†ä½ç½®åœˆå®šèŒƒå›´ï¼Œå†åœ¨èŒƒå›´å†…æ‰¾ã€‚
    """
    try:
        u_prov = str(user_row[mapping['prov']]) if mapping['prov'] and pd.notna(user_row[mapping['prov']]) else ''
        u_city = str(user_row[mapping['city']]) if mapping['city'] and pd.notna(user_row[mapping['city']]) else ''
        u_dist = str(user_row[mapping['dist']]) if mapping['dist'] and pd.notna(user_row[mapping['dist']]) else ''
        
        target_indices = set()
        scope_desc = ""

        # --- 1. åœ°ç†åœˆäºº (Geographic Fencing) ---
        if u_dist and u_dist in dist_groups:
            dist_indices = set(dist_groups[u_dist])
            # å¦‚æœæœ‰åŸå¸‚ä¿¡æ¯ï¼Œåšäº¤é›†éªŒè¯ï¼ˆé˜²æ­¢åŒååŒºï¼Œå¦‚â€œåŸå…³åŒºâ€ï¼‰
            if u_city and u_city in city_groups:
                city_indices = set(city_groups[u_city])
                intersection = dist_indices.intersection(city_indices)
                target_indices = intersection if intersection else dist_indices
                scope_desc = f"ç²¾å‡†åŒºåŸŸ: {u_city}{u_dist}"
            else:
                target_indices = dist_indices
                scope_desc = f"åŒºåŸŸ: {u_dist}"
        
        elif u_city and u_city in city_groups:
            target_indices = set(city_groups[u_city])
            scope_desc = f"åŸå¸‚: {u_city}"
            
        elif u_prov and u_prov in prov_groups:
            target_indices = set(prov_groups[u_prov])
            scope_desc = f"çœä»½: {u_prov}"
            
        else:
            target_indices = set(df_master.index)
            scope_desc = "å…¨å›½èŒƒå›´"

        # --- 2. è¿é”ä¸‹é’» (Chain Drill-down) ---
        # å¦‚æœæ‰¾åˆ°äº†åœ°ç†èŒƒå›´ï¼Œä¸”ç”¨æˆ·æœ‰è¿é”åï¼Œæˆ‘ä»¬å¼ºåˆ¶æŠŠè¯¥åŒºåŸŸå†…è¯¥è¿é”çš„æ‰€æœ‰åº—éƒ½æ‹‰è¿›æ¥
        # å³ä½¿åå­—åŒ¹é…åº¦ä½ï¼Œä¹Ÿè¦æ‹‰è¿›æ¥ç»™ AI çœ‹åœ°å€
        force_chain_indices = set()
        if chain_name and chain_name in chain_groups:
            chain_indices = set(chain_groups[chain_name])
            force_chain_indices = chain_indices.intersection(target_indices)

        # --- 3. å€™é€‰åˆæˆ ---
        candidates_indices = set()
        candidates_indices.update(force_chain_indices) 
        
        # å¦‚æœè¿˜æ²¡æ‰¾åˆ°æˆ–è€…éœ€è¦æ›´å¤šæ¨¡ç³Šå€™é€‰é¡¹
        if target_indices:
            search_pool = list(target_indices)
            # å®‰å…¨åˆ‡ç‰‡ï¼šå¦‚æœæ± å­å¤ªå¤§ï¼Œä¸”å·²ç»æœ‰è¿é”å€™é€‰ï¼Œå°±å°‘æœç‚¹å…¨å±€
            if len(search_pool) > 3000 and len(force_chain_indices) > 0:
                 search_pool = search_pool[:1000] 

            current_scope_df = df_master.loc[search_pool]
            choices = current_scope_df['æ ‡å‡†åç§°'].fillna('').astype(str).to_dict()
            
            # æ¨¡ç³Šæœç´¢å‰ 5 åè¡¥å……è¿›å»
            results = process.extract(search_name, choices, limit=5, scorer=fuzz.WRatio)
            for r in results:
                candidates_indices.add(r[2])

        return list(candidates_indices), scope_desc
    
    except Exception as e:
        return [], "Error"

def ai_match_row_v4(client, user_row, search_name, chain_name, scope_desc, candidates_df):
    """
    ğŸŒŸ V4 Prompt: å¼ºåŒ–åœ°å€äº¤å‰éªŒè¯ä¸ç¬¦å·è¯†åˆ«
    """
    cols_to_keep = ['esid', 'æ ‡å‡†åç§°', 'æœºæ„ç±»å‹', 'çœ', 'å¸‚', 'åŒº', 'åœ°å€', 'è¿é”å“ç‰Œ']
    valid_cols = [c for c in cols_to_keep if c in candidates_df.columns]
    candidates_json = candidates_df[valid_cols].to_json(orient="records", force_ascii=False)
    
    user_raw_addr = str(user_row.get('åœ°å€åˆ—_raw', ''))
    
    prompt = f"""
    ã€è§’è‰²ã€‘ä½ æ˜¯ä¸€ä¸ªæåº¦ä¸¥è°¨çš„ä¸»æ•°æ®åŒ¹é…ä¸“å®¶ã€‚
    
    ã€å¾…åŒ¹é…ç›®æ ‡ã€‘
    - ç»„åˆåç§°: "{search_name}"
    - è¿é”å“ç‰Œ: "{chain_name}" (å¦‚æœä¸ºç©ºåˆ™æ— )
    - æ‰€åœ¨åŒºåŸŸ: {scope_desc}
    - åŸå§‹åœ°å€: "{user_raw_addr}" (å…³é”®çº¿ç´¢!)
    
    ã€å€™é€‰ä¸»æ•°æ®åˆ—è¡¨ã€‘(å·²é™åˆ¶åœ¨åŒåŒºåŸŸå†…)
    {candidates_json}
    
    ã€æ€ç»´é“¾è§„åˆ™ - å¿…é¡»ä¸¥æ ¼æ‰§è¡Œã€‘:
    1. **ç¬¦å·/çŸ­åè¯†åˆ«**: 
       - ç”¨æˆ·çš„åç§°å¯èƒ½æç®€ï¼Œä¾‹å¦‚â€œä¸€åº—â€ã€â€œä¸‰åˆ†åº—â€ã€â€œä¸œé—¨åº—â€ã€‚
       - **å¿…é¡»**å»å€™é€‰æ•°æ®çš„ã€æ ‡å‡†åç§°ã€‘å’Œ**ã€åœ°å€ã€‘**ä¸­å¯»æ‰¾åŒ…å«è¿™äº›å…³é”®è¯çš„è®°å½•ã€‚
       - ä¾‹å¦‚ï¼šç”¨æˆ·è¾“å…¥â€œä¸€åº—â€ï¼Œå€™é€‰åœ°å€â€œXXè·¯10å·æµ·ç‹æ˜Ÿè¾°ç¬¬ä¸€åˆ†åº—â€ï¼Œè¿™å°±æ˜¯åŒ¹é…ï¼
       
    2. **åœ°å€äº¤å‰éªŒè¯**: 
       - å¦‚æœåç§°åŒ¹é…åº¦ä¸é«˜ï¼Œä½†ã€åŸå§‹åœ°å€ã€‘ä¸å€™é€‰çš„ã€åœ°å€ã€‘é«˜åº¦å»åˆï¼ˆå¦‚åŒè·¯åã€åŒé—¨ç‰Œï¼‰ï¼Œåˆ™åˆ¤å®šä¸º Highã€‚
       
    3. **è¿é”ä¸€è‡´æ€§**:
       - å¦‚æœç”¨æˆ·æŒ‡å®šäº†è¿é”å“ç‰Œï¼Œå€™é€‰å¿…é¡»å±äºè¯¥è¿é”ï¼ˆæˆ–åç§°åŒ…å«è¯¥è¿é”ï¼‰ã€‚
       - ä¸¥ç¦å°†Aè¿é”çš„åº—åŒ¹é…ç»™Bè¿é”ã€‚
       
    4. **æ€»éƒ¨é™·é˜±**:
       - é™¤éç”¨æˆ·æ‰¾â€œæ€»éƒ¨â€ï¼Œå¦åˆ™ä¸è¦åŒ¹é…â€œæ€»å…¬å¸/è‚¡ä»½æœ‰é™å…¬å¸â€ã€‚è¯·ä¼˜å…ˆæ‰¾å…·ä½“çš„é—¨åº—ã€‚
    
    ã€è¾“å‡º JSONã€‘:
    {{ 
      "match_esid": "ESIDæˆ–null", 
      "match_name": "æ ‡å‡†åç§°", 
      "match_type": "æœºæ„ç±»å‹", 
      "confidence": "High/Mid/Low", 
      "reason": "è¯´æ˜åŒ¹é…ä¾æ®ï¼Œå¦‚'åœ°å€è·¯åå®Œå…¨ä¸€è‡´'æˆ–'åç§°åç¼€åŒ¹é…'" 
    }}
    """
    return safe_generate(client, prompt)

# ================= 3. é¡µé¢ UI =================

st.markdown("""
    <style>
    .stApp {background-color: #F8F9FA;}
    .stat-card {background: #ffffff; padding: 15px; border-radius: 8px; border: 1px solid #e5e7eb; box-shadow: 0 1px 2px rgba(0,0,0,0.05);}
    .big-num {font-size: 24px; font-weight: bold; color: #1e40af;}
    .task-box {background-color: #eff6ff; padding: 12px; border-radius: 6px; margin-bottom: 8px; border-left: 5px solid #2563eb; font-size:14px;}
    .running-box {background-color: #fff7ed; border: 2px solid #f97316; padding: 15px; border-radius: 8px;}
    </style>
    <div style="font-size: 26px; font-weight: bold; color: #1E3A8A; margin-bottom: 20px;">
    ğŸ§¬ LinkMed Matcher (Smart Strategy)
    </div>
""", unsafe_allow_html=True)

client = get_client()

# åŠ è½½æ•°æ®
df_master, prov_groups, city_groups, dist_groups, chain_groups = pd.DataFrame(), {}, {}, {}, {}
if os.path.exists(LOCAL_MASTER_FILE):
    with st.spinner(f"æ­£åœ¨åŠ è½½ä¸»æ•°æ®å¼•æ“..."):
        df_master, prov_groups, city_groups, dist_groups, chain_groups = load_master_data()
else:
    st.warning(f"âš ï¸ æ–‡ä»¶ç¼ºå¤±: `{LOCAL_MASTER_FILE}`")

# --- Sidebar ---
with st.sidebar:
    st.header("ğŸ—„ï¸ æ§åˆ¶å°")
    
    # ğŸ›‘ åœæ­¢æŒ‰é’® (æ ¸å¿ƒåŠŸèƒ½)
    if st.session_state.is_running:
        if st.button("ğŸ›‘ åœæ­¢å¹¶ç»“ç®—ç»“æœ", type="primary", use_container_width=True):
            request_stop()
    else:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºé‡ç½®", type="secondary", use_container_width=True):
            reset_app()
            
    st.divider()
    if not df_master.empty:
        st.success(f"ä¸»æ•°æ®: {len(df_master)} æ¡")

# --- 1. ä¸Šä¼ ä¸æ˜ å°„ ---
if not st.session_state.mapping_confirmed:
    st.markdown("### ğŸ“‚ 1. ä¸Šä¼ ä¸å­—æ®µç¡®è®¤")
    uploaded_file = st.file_uploader("Excel/CSV", type=['xlsx', 'csv'], key=st.session_state.uploader_key)

    if uploaded_file and not df_master.empty:
        try:
            if uploaded_file.name.endswith('.csv'): df_user = pd.read_csv(uploaded_file)
            else: df_user = pd.read_excel(uploaded_file)
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            st.stop()
        
        # è‡ªåŠ¨æ˜ å°„æ¨æ–­
        if 'map_config' not in st.session_state or st.session_state.get('last_file') != uploaded_file.name:
            with st.spinner("AI æ­£åœ¨è¯†åˆ«è¡¨å¤´..."):
                st.session_state.map_config = smart_map_columns(client, df_user)
                st.session_state.last_file = uploaded_file.name
        
        map_res = st.session_state.map_config
        cols = df_user.columns.tolist()
        
        st.info("ğŸ‘‡ è¯·åŠ¡å¿…ç¡®è®¤ AI è¯†åˆ«çš„å­—æ®µæ˜¯å¦æ­£ç¡®ï¼Œå¦‚æœ‰è¯¯è¯·æ‰‹åŠ¨ä¿®æ”¹ï¼š")
        
        c1, c2, c3 = st.columns(3)
        def get_idx(key): return cols.index(map_res.get(key)) if map_res.get(key) in cols else 0
        
        with c1:
            col_name = st.selectbox("ğŸ“ è¯æˆ¿åç§° (å¿…é€‰)", cols, index=get_idx('name_col'), help="ä¹Ÿå°±æ˜¯ç»ˆç«¯åç§°")
            col_chain = st.selectbox("ğŸ”— è¿é”åç§° (å¯é€‰)", [None]+cols, index=cols.index(map_res['chain_col'])+1 if map_res.get('chain_col') in cols else 0)
        with c2:
            col_prov = st.selectbox("ğŸ—ºï¸ çœä»½", [None]+cols, index=cols.index(map_res['prov_col'])+1 if map_res.get('prov_col') in cols else 0)
            col_city = st.selectbox("ğŸ™ï¸ åŸå¸‚", [None]+cols, index=cols.index(map_res['city_col'])+1 if map_res.get('city_col') in cols else 0)
        with c3:
            col_dist = st.selectbox("ğŸ˜ï¸ åŒºå¿", [None]+cols, index=cols.index(map_res['dist_col'])+1 if map_res.get('dist_col') in cols else 0)
            col_addr = st.selectbox("ğŸ  è¯¦ç»†åœ°å€ (é‡è¦)", [None]+cols, index=cols.index(map_res['addr_col'])+1 if map_res.get('addr_col') in cols else 0)

        if st.button("âœ… ç¡®è®¤å­—æ®µæ˜ å°„å¹¶ç»§ç»­", type="primary"):
            st.session_state.user_mapping = {
                'prov': col_prov, 'city': col_city, 'dist': col_dist, 
                'addr': col_addr, 'chain': col_chain, 'name': col_name
            }
            # å­˜å…¥åŸå§‹æ•°æ®å¤‡ç”¨
            st.session_state.raw_df_user = df_user
            st.session_state.mapping_confirmed = True
            st.rerun()

# --- 2. é¢„å¤„ç†ä¸åˆ†åŒ… ---
elif st.session_state.mapping_confirmed and not st.session_state.prep_done:
    st.markdown("### âš¡ 2. é¢„å¤„ç†åˆ†æ")
    
    mapping = st.session_state.user_mapping
    df_user = st.session_state.raw_df_user
    
    with st.spinner("æ­£åœ¨è¿›è¡Œæ•°æ®æ¸…æ´—ã€æ’åºä¸å…¨å­—åŒ¹é…..."):
        try:
            # 1. å®‰å…¨æ¸…æ´—
            df_safe = df_user.copy()
            for k, c in mapping.items():
                if c: df_safe[c] = df_safe[c].astype(str).replace('nan', '').str.strip()
            
            # 2. åœ°ç†æ’åº (è®©åŒåŒºæ•°æ®åœ¨ä¸€èµ·)
            sort_cols = []
            if mapping['prov']: sort_cols.append(mapping['prov'])
            if mapping['city']: sort_cols.append(mapping['city'])
            if mapping['dist']: sort_cols.append(mapping['dist'])
            if sort_cols:
                df_safe = df_safe.sort_values(by=sort_cols).reset_index(drop=True)

            # 3. å‘é‡åŒ–å…¨å­—åŒ¹é…
            master_exact = df_master.drop_duplicates(subset=['æ ‡å‡†åç§°']).set_index('æ ‡å‡†åç§°').to_dict('index')
            
            def check_exact(row):
                raw = row[mapping['name']]
                chain = row[mapping['chain']] if mapping['chain'] else ""
                search = raw
                if chain and chain not in raw: search = f"{chain} {raw}"
                
                if search in master_exact:
                    m = master_exact[search]
                    return pd.Series([True, m.get('esid'), search, m.get('æœºæ„ç±»å‹'), "High", "å…¨å­—åŒ¹é…", "ç²¾ç¡®å‘½ä¸­"])
                return pd.Series([False, None, None, None, None, None, None])

            match_results = df_safe.apply(check_exact, axis=1)
            match_results.columns = ['is_match', 'åŒ¹é…ESID', 'åŒ¹é…æ ‡å‡†å', 'æœºæ„ç±»å‹', 'ç½®ä¿¡åº¦', 'åŒ¹é…æ–¹å¼', 'ç†ç”±']
            
            df_combined = pd.concat([df_safe, match_results], axis=1)
            
            # æ‹†åˆ†
            df_exact = df_combined[df_combined['is_match'] == True].drop(columns=['is_match'])
            df_rem = df_combined[df_combined['is_match'] == False].drop(columns=['is_match', 'åŒ¹é…ESID', 'åŒ¹é…æ ‡å‡†å', 'æœºæ„ç±»å‹', 'ç½®ä¿¡åº¦', 'åŒ¹é…æ–¹å¼', 'ç†ç”±'])
            
            st.session_state.df_exact = df_exact
            st.session_state.total_rem = len(df_rem)
            
            # æ‹†ä»»åŠ¡åŒ… (æ¯åŒ… 800 æ¡ï¼Œç¨å¾®å°ä¸€ç‚¹é˜²è¶…æ—¶)
            BATCH_SIZE = 800
            batches = []
            if len(df_rem) > 0:
                num_batches = math.ceil(len(df_rem) / BATCH_SIZE)
                for i in range(num_batches):
                    batches.append(df_rem.iloc[i*BATCH_SIZE : (i+1)*BATCH_SIZE])
            
            st.session_state.batches = batches
            st.session_state.prep_done = True
            st.session_state.match_stats['exact'] = len(df_exact)
            st.rerun()
            
        except Exception as e:
            st.error(f"é¢„å¤„ç†é”™è¯¯: {e}")
            st.stop()

# --- 3. ä»»åŠ¡æ‰§è¡Œä¸ç›‘æ§ ---
elif st.session_state.prep_done and not st.session_state.final_result_df is not None:
    # è¿™é‡Œå¤„ç†è¿˜æ²¡è·‘å®Œï¼Œæˆ–è€…è¿˜æ²¡å¼€å§‹è·‘çš„æƒ…å†µ
    # å¦‚æœå·²ç»æœ‰ç»“æœäº†(final_result_df not None)ï¼Œå°±å»ç»“æœé¡µ
    # å¦‚æœè¿˜æ²¡æœ‰ï¼Œå°±åœ¨è¿™é‡Œ
    
    # è¿˜æ²¡ç‚¹å¼€å§‹
    if not st.session_state.is_running and len(st.session_state.accumulated_results) == 0:
        count_exact = len(st.session_state.df_exact)
        count_rem = st.session_state.total_rem
        batches = st.session_state.batches
        
        st.info(f"âœ… è‡ªåŠ¨å‘½ä¸­ {count_exact} è¡Œã€‚å‰©ä½™ {count_rem} è¡Œå¾… AI æ·±åº¦åŒ¹é…ã€‚")
        
        if count_rem > 0:
            st.markdown(f"**å·²æ‹†åˆ†ä¸º {len(batches)} ä¸ªä»»åŠ¡åŒ…ï¼Œç‚¹å‡»å¯åŠ¨åå°†è‡ªåŠ¨æ¥åŠ›æ‰§è¡Œã€‚**")
            if st.button(f"ğŸš€ å¯åŠ¨æ·±åº¦åŒ¹é… ({len(batches)} åŒ…)", type="primary"):
                st.session_state.is_running = True
                st.session_state.current_batch_idx = 0
                st.session_state.stop_requested = False
                st.rerun()
        else:
            if st.button("âœ¨ ç›´æ¥ç”Ÿæˆç»“æœ", type="primary"):
                st.session_state.final_result_df = st.session_state.df_exact
                st.rerun()

    # æ­£åœ¨è¿è¡Œä¸­ (Relay Loop)
    elif st.session_state.is_running:
        
        batches = st.session_state.batches
        curr_idx = st.session_state.current_batch_idx
        mapping = st.session_state.user_mapping
        
        if curr_idx < len(batches):
            current_batch = batches[curr_idx]
            batch_num = curr_idx + 1
            
            st.markdown(f"""
            <div class='running-box'>
                <h3>ğŸ”„ æ­£åœ¨å¤„ç†ä»»åŠ¡åŒ… {batch_num} / {len(batches)}</h3>
                <p>å½“å‰åŒ…åŒ…å« {len(current_batch)} è¡Œæ•°æ®ã€‚<b>ç‚¹å‡»å·¦ä¾§â€œğŸ›‘ åœæ­¢å¹¶ç»“ç®—â€å¯éšæ—¶ä¸­æ–­ä¿å­˜ã€‚</b></p>
            </div>
            """, unsafe_allow_html=True)
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            batch_results = []
            
            for i, (orig_idx, row) in enumerate(current_batch.iterrows()):
                
                # ğŸ”¥ æ£€æŸ¥åœæ­¢ä¿¡å·
                if st.session_state.stop_requested:
                    break
                
                try:
                    # å‡†å¤‡æ•°æ®
                    raw_name = str(row[mapping['name']])
                    chain_name = str(row[mapping['chain']]) if mapping['chain'] else ""
                    search_name = raw_name
                    if chain_name and chain_name not in raw_name: search_name = f"{chain_name} {raw_name}"
                    
                    row_with_meta = row.copy()
                    if mapping['addr']: row_with_meta['åœ°å€åˆ—_raw'] = str(row[mapping['addr']])

                    # 1. ç­–ç•¥å‡çº§ï¼šåˆ†å±‚æ£€ç´¢
                    indices, scope_desc = get_candidates_hierarchical(
                        search_name, chain_name, df_master, 
                        prov_groups, city_groups, dist_groups, chain_groups, 
                        row, mapping
                    )
                    
                    base_res = row.to_dict()
                    
                    if not indices:
                        base_res.update({"åŒ¹é…ESID": None, "åŒ¹é…æ ‡å‡†å": None, "æœºæ„ç±»å‹": None, "ç½®ä¿¡åº¦": "Low", "åŒ¹é…æ–¹å¼": "æ— ç»“æœ", "ç†ç”±": f"åŒºåŸŸ[{scope_desc}]æ— åŒ¹é…"})
                        st.session_state.match_stats['no_match'] += 1
                    else:
                        try:
                            candidates = df_master.loc[indices].copy()
                        except:
                            candidates = pd.DataFrame()

                        if candidates.empty:
                            base_res.update({"åŒ¹é…ESID": None, "åŒ¹é…æ ‡å‡†å": None, "æœºæ„ç±»å‹": None, "ç½®ä¿¡åº¦": "Low", "åŒ¹é…æ–¹å¼": "æ— ç»“æœ", "ç†ç”±": "ç´¢å¼•å¼‚å¸¸"})
                            st.session_state.match_stats['no_match'] += 1
                        else:
                            # 2. ç­–ç•¥å‡çº§ï¼šV4 Prompt (å«åœ°å€äº¤å‰éªŒè¯)
                            ai_res = ai_match_row_v4(client, row_with_meta, search_name, chain_name, scope_desc, candidates)
                            if isinstance(ai_res, list): ai_res = ai_res[0] if ai_res else {}
                            
                            conf = ai_res.get("confidence", "Low")
                            base_res.update({
                                "åŒ¹é…ESID": ai_res.get("match_esid"),
                                "åŒ¹é…æ ‡å‡†å": ai_res.get("match_name"),
                                "æœºæ„ç±»å‹": ai_res.get("match_type"),
                                "ç½®ä¿¡åº¦": conf,
                                "åŒ¹é…æ–¹å¼": f"æ¨¡å‹ ({scope_desc})",
                                "ç†ç”±": ai_res.get("reason")
                            })
                            
                            if conf == "High": st.session_state.match_stats['high'] += 1
                            elif conf == "Mid": st.session_state.match_stats['mid'] += 1
                            else: st.session_state.match_stats['low'] += 1
                            
                            time.sleep(1.5) # å†·å´
                    
                    batch_results.append(base_res)
                    progress_bar.progress((i + 1) / len(current_batch))
                    status_text.caption(f"æ­£åœ¨åŒ¹é…: {search_name}")
                    
                except Exception as e:
                    pass
            
            # --- Batch End ---
            # å­˜å…¥æ€»æ± 
            st.session_state.accumulated_results.extend(batch_results)
            
            # å¦‚æœæ˜¯ç‚¹äº†åœæ­¢
            if st.session_state.stop_requested:
                st.warning("ğŸ›‘ ä»»åŠ¡å·²åœæ­¢ã€‚æ­£åœ¨ç”Ÿæˆå·²å®Œæˆéƒ¨åˆ†çš„æŠ¥å‘Š...")
                st.session_state.is_running = False
                # è§¦å‘åˆå¹¶
                df_exact = st.session_state.df_exact
                df_ai = pd.DataFrame(st.session_state.accumulated_results)
                final = pd.concat([df_exact, df_ai], ignore_index=True) if not df_ai.empty else df_exact
                st.session_state.final_result_df = final
                st.rerun()
            else:
                # æ­£å¸¸å®Œæˆä¸€ä¸ªåŒ…
                st.session_state.current_batch_idx += 1
                st.rerun()
        
        else:
            # å…¨éƒ¨åŒ…è·‘å®Œ
            st.success("ğŸ‰ å…¨éƒ¨ä»»åŠ¡å®Œæˆï¼")
            st.session_state.is_running = False
            df_exact = st.session_state.df_exact
            df_ai = pd.DataFrame(st.session_state.accumulated_results)
            final = pd.concat([df_exact, df_ai], ignore_index=True) if not df_ai.empty else df_exact
            st.session_state.final_result_df = final
            st.rerun()

# --- 4. ç»“æœå±•ç¤º ---
if st.session_state.final_result_df is not None:
    s = st.session_state.match_stats
    total = len(st.session_state.final_result_df)
    if total == 0: total = 1
    
    st.markdown("### ğŸ“Š åŒ¹é…ç»Ÿè®¡æŠ¥å‘Š")
    
    exact_val = s.get('exact', 0)
    exact_pct = exact_val / total
    
    # åŠ¨æ€è®¡ç®—æ¨¡å‹å·²è·‘çš„æ•°é‡
    model_done = s.get('high', 0) + s.get('mid', 0) + s.get('low', 0)
    model_denom = model_done if model_done > 0 else 1
    
    # æ˜¾ç¤ºç»Ÿè®¡å¡ç‰‡
    c1, c2, c3, c4, c5 = st.columns(5)
    with c1: st.metric("ğŸ¯ å…¨å­—åŒ¹é…", f"{exact_val}", f"{exact_pct:.1%}")
    with c2: st.metric("ğŸ¤– æ¨¡å‹å·²è·‘", f"{model_done}", f"{(model_done/(st.session_state.total_rem if st.session_state.total_rem else 1)):.1%}")
    with c3: st.metric("ğŸ”¥ High", f"{s.get('high', 0)}", f"{s.get('high', 0)/model_denom:.1%}")
    with c4: st.metric("âš–ï¸ Mid", f"{s.get('mid', 0)}", f"{s.get('mid', 0)/model_denom:.1%}")
    with c5: st.metric("âš ï¸ Low", f"{s.get('low', 0)}", f"{s.get('low', 0)/model_denom:.1%}")

    st.divider()
    
    def color_row(row):
        conf = row.get('ç½®ä¿¡åº¦')
        if conf == 'High': return ['background-color: #dcfce7'] * len(row)
        if conf == 'Mid': return ['background-color: #fef9c3'] * len(row)
        if conf == 'Low': return ['background-color: #fee2e2'] * len(row)
        return [''] * len(row)

    df_show = st.session_state.final_result_df
    st.dataframe(df_show.style.apply(color_row, axis=1), use_container_width=True)
    
    csv = df_show.to_csv(index=False).encode('utf-8-sig')
    st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœæ–‡ä»¶", csv, "linkmed_final_result.csv", "text/csv", type="primary")
